// SymCryptSha256AppendBlocks_ul1 
 
_BYTE *__fastcall SymCryptSha256AppendBlocks_ul1(int *a1, unsigned int *a2, unsigned int a3, unsigned int *a4)
{
  int v5; // r6
  int v6; // r7
  int v7; // r5
  int v8; // r9
  int v9; // r10
  int v10; // r8
  int v12; // r1
  int v13; // r0
  unsigned int v14; // r4
  int v15; // r0
  int v16; // lr
  int v17; // r4
  unsigned int v18; // r1
  int v19; // r0
  int v20; // r8
  int v21; // r5
  int v22; // r0
  int v23; // r9
  int v24; // r6
  unsigned int v25; // r1
  int v26; // r0
  int v27; // r10
  int v28; // r7
  unsigned int v29; // r1
  int v30; // r0
  int v31; // lr
  int v32; // r4
  unsigned int v33; // r1
  int v34; // r0
  int v35; // r8
  int v36; // r5
  unsigned int v37; // r1
  int v38; // r0
  int v39; // r9
  int v40; // r6
  unsigned int v41; // r1
  int v42; // r0
  int v43; // r10
  int v44; // r7
  unsigned int v45; // r1
  int v46; // r0
  int v47; // lr
  int v48; // r4
  int v49; // r0
  int v50; // r8
  int v51; // r5
  unsigned int v52; // r1
  int v53; // r0
  int v54; // r9
  int v55; // r6
  unsigned int v56; // r1
  int v57; // r0
  int v58; // r10
  int v59; // r7
  unsigned int v60; // r1
  int v61; // r0
  int v62; // lr
  int v63; // r0
  int v64; // r8
  int v65; // r5
  int v66; // r0
  int v67; // r9
  int v68; // r6
  int v69; // r4
  unsigned int v70; // r1
  int v71; // r0
  int v72; // r10
  int v73; // r7
  unsigned int v74; // r0
  unsigned int v75; // r4
  unsigned int v76; // lr
  unsigned int v77; // r0
  unsigned int v78; // r8
  unsigned int v79; // r5
  unsigned int v80; // r0
  unsigned int v81; // r9
  unsigned int v82; // r6
  unsigned int v83; // r0
  unsigned int v84; // r10
  unsigned int v85; // r7
  unsigned int v86; // r0
  unsigned int v87; // lr
  unsigned int v88; // r4
  unsigned int v89; // r0
  unsigned int v90; // r8
  unsigned int v91; // r5
  unsigned int v92; // r0
  unsigned int v93; // r9
  unsigned int v94; // r6
  unsigned int v95; // r0
  unsigned int v96; // r10
  unsigned int v97; // r7
  unsigned int v98; // r0
  unsigned int v99; // lr
  unsigned int v100; // r4
  unsigned int v101; // r0
  unsigned int v102; // r8
  unsigned int v103; // r5
  unsigned int v104; // r0
  unsigned int v105; // r9
  unsigned int v106; // r6
  unsigned int v107; // r0
  unsigned int v108; // r10
  unsigned int v109; // r7
  unsigned int v110; // r0
  unsigned int v111; // r0
  unsigned int v112; // r0
  int v113; // r3
  unsigned int v114; // r0
  bool v115; // zf
  int v117; // [sp+0h] [bp-100h]
  int *v118; // [sp+0h] [bp-100h]
  unsigned int *v119; // [sp+4h] [bp-FCh]
  unsigned int v120; // [sp+8h] [bp-F8h]
  unsigned int v121; // [sp+Ch] [bp-F4h]
  unsigned int v122; // [sp+10h] [bp-F0h]
  unsigned int v123; // [sp+14h] [bp-ECh]
  unsigned int v124; // [sp+18h] [bp-E8h]
  unsigned int v125; // [sp+1Ch] [bp-E4h]
  unsigned int v126; // [sp+20h] [bp-E0h]
  unsigned int v127; // [sp+24h] [bp-DCh]
  unsigned int v128; // [sp+28h] [bp-D8h]
  unsigned int v129; // [sp+2Ch] [bp-D4h]
  unsigned int v130; // [sp+30h] [bp-D0h]
  unsigned int v131; // [sp+34h] [bp-CCh]
  unsigned int v132; // [sp+38h] [bp-C8h]
  unsigned int v133; // [sp+3Ch] [bp-C4h]
  unsigned int v134; // [sp+40h] [bp-C0h]
  unsigned int v135; // [sp+44h] [bp-BCh]
  int v136; // [sp+48h] [bp-B8h]
  int v137; // [sp+4Ch] [bp-B4h]
  int v138; // [sp+50h] [bp-B0h]
  unsigned int v139; // [sp+54h] [bp-ACh]
  int v140; // [sp+58h] [bp-A8h]
  unsigned int v141; // [sp+5Ch] [bp-A4h]
  int v142; // [sp+60h] [bp-A0h]
  int v143; // [sp+64h] [bp-9Ch]
  int v144; // [sp+68h] [bp-98h]
  int v145; // [sp+6Ch] [bp-94h]
  int v146; // [sp+70h] [bp-90h]
  int v149[24]; // [sp+A0h] [bp-60h] BYREF

  v5 = a1[1];
  v6 = *a1;
  v7 = a1[2];
  v8 = a1[5];
  v9 = a1[4];
  v10 = a1[6];
  v12 = a1[3];
  v13 = a1[7];
  v139 = a3;
  v119 = a2;
  if ( a3 >= 0x40 )
  {
    v140 = v7;
    v141 = a3 >> 6;
    v137 = v13;
    v138 = v6;
    v143 = v5;
    v144 = v12;
    v142 = v9;
    v145 = v10;
    v146 = v8;
    do
    {
      v14 = bswap32(*a2);
      v15 = ((v10 ^ v8) & v9 ^ v10) + (__ROR4__(v9, 25) ^ __ROR4__(v9, 11) ^ __ROR4__(v9, 6)) + v13 + v14 + 1116352408;
      v16 = v15 + v12;
      v131 = v14;
      v17 = (v7 & v5 | (v7 | v5) & v6) + (__ROR4__(v6, 22) ^ __ROR4__(v6, 13) ^ __ROR4__(v6, 2)) + v15;
      v18 = bswap32(v119[1]);
      v19 = ((v8 ^ v9) & v16 ^ v8) + (__ROR4__(v16, 25) ^ __ROR4__(v16, 11) ^ __ROR4__(v16, 6)) + v10 + v18 + 1899447441;
      v133 = v18;
      v20 = v19 + v7;
      v21 = (v5 & v6 | (v5 | v6) & v17) + (__ROR4__(v17, 22) ^ __ROR4__(v17, 13) ^ __ROR4__(v17, 2)) + v19;
      v122 = bswap32(v119[2]);
      v22 = ((v9 ^ v16) & v20 ^ v9)
          + (__ROR4__(v20, 25) ^ __ROR4__(v20, 11) ^ __ROR4__(v20, 6))
          + v8
          + v122
          - 1245643825;
      v23 = v22 + v5;
      v24 = (v17 & v6 | (v17 | v6) & v21) + (__ROR4__(v21, 22) ^ __ROR4__(v21, 13) ^ __ROR4__(v21, 2)) + v22;
      v25 = bswap32(v119[3]);
      v26 = ((v16 ^ v20) & v23 ^ v16)
          + (__ROR4__(v23, 25) ^ __ROR4__(v23, 11) ^ __ROR4__(v23, 6))
          + v9
          + v25
          - 373957723;
      v132 = v25;
      v27 = v26 + v6;
      v28 = (v17 & v21 | (v17 | v21) & v24) + (__ROR4__(v24, 22) ^ __ROR4__(v24, 13) ^ __ROR4__(v24, 2)) + v26;
      v29 = bswap32(v119[4]);
      v30 = ((v20 ^ v23) & v27 ^ v20)
          + (__ROR4__(v27, 25) ^ __ROR4__(v27, 11) ^ __ROR4__(v27, 6))
          + v16
          + v29
          + 961987163;
      v130 = v29;
      v31 = v17 + v30;
      v32 = (v21 & v24 | (v21 | v24) & v28) + (__ROR4__(v28, 22) ^ __ROR4__(v28, 13) ^ __ROR4__(v28, 2)) + v30;
      v33 = bswap32(v119[5]);
      v34 = ((v23 ^ v27) & v31 ^ v23)
          + (__ROR4__(v31, 25) ^ __ROR4__(v31, 11) ^ __ROR4__(v31, 6))
          + v20
          + v33
          + 1508970993;
      v134 = v33;
      v35 = v21 + v34;
      v36 = (v24 & v28 | (v24 | v28) & v32) + (__ROR4__(v32, 22) ^ __ROR4__(v32, 13) ^ __ROR4__(v32, 2)) + v34;
      v37 = bswap32(v119[6]);
      v38 = ((v31 ^ v27) & v35 ^ v27)
          + (__ROR4__(v35, 25) ^ __ROR4__(v35, 11) ^ __ROR4__(v35, 6))
          + v23
          + v37
          - 1841331548;
      v121 = v37;
      v39 = v24 + v38;
      v40 = (v28 & v32 | (v28 | v32) & v36) + (__ROR4__(v36, 22) ^ __ROR4__(v36, 13) ^ __ROR4__(v36, 2)) + v38;
      v41 = bswap32(v119[7]);
      v42 = ((v31 ^ v35) & v39 ^ v31)
          + (__ROR4__(v39, 25) ^ __ROR4__(v39, 11) ^ __ROR4__(v39, 6))
          + v27
          + v41
          - 1424204075;
      v125 = v41;
      v43 = v28 + v42;
      v44 = (v32 & v36 | (v32 | v36) & v40) + (__ROR4__(v40, 22) ^ __ROR4__(v40, 13) ^ __ROR4__(v40, 2)) + v42;
      v45 = bswap32(v119[8]);
      v46 = ((v35 ^ v39) & v43 ^ v35)
          + (__ROR4__(v43, 25) ^ __ROR4__(v43, 11) ^ __ROR4__(v43, 6))
          + v31
          + v45
          - 670586216;
      v120 = v45;
      v47 = v46 + v32;
      v48 = (v36 & v40 | (v36 | v40) & v44) + (__ROR4__(v44, 22) ^ __ROR4__(v44, 13) ^ __ROR4__(v44, 2)) + v46;
      v124 = bswap32(v119[9]);
      v49 = ((v39 ^ v43) & v47 ^ v39)
          + (__ROR4__(v47, 25) ^ __ROR4__(v47, 11) ^ __ROR4__(v47, 6))
          + v35
          + v124
          + 310598401;
      v50 = v49 + v36;
      v51 = (v40 & v44 | (v40 | v44) & v48) + (__ROR4__(v48, 22) ^ __ROR4__(v48, 13) ^ __ROR4__(v48, 2)) + v49;
      v52 = bswap32(v119[10]);
      v53 = ((v43 ^ v47) & v50 ^ v43)
          + (__ROR4__(v50, 25) ^ __ROR4__(v50, 11) ^ __ROR4__(v50, 6))
          + v39
          + v52
          + 607225278;
      v126 = v52;
      v54 = v53 + v40;
      v55 = (v48 & v44 | (v48 | v44) & v51) + (__ROR4__(v51, 22) ^ __ROR4__(v51, 13) ^ __ROR4__(v51, 2)) + v53;
      v56 = bswap32(v119[11]);
      v57 = ((v47 ^ v50) & v54 ^ v47)
          + (__ROR4__(v54, 25) ^ __ROR4__(v54, 11) ^ __ROR4__(v54, 6))
          + v43
          + v56
          + 1426881987;
      v58 = v57 + v44;
      v128 = v56;
      v59 = (v48 & v51 | (v48 | v51) & v55) + (__ROR4__(v55, 22) ^ __ROR4__(v55, 13) ^ __ROR4__(v55, 2)) + v57;
      v60 = bswap32(v119[12]);
      v61 = ((v50 ^ v54) & v58 ^ v50)
          + (__ROR4__(v58, 25) ^ __ROR4__(v58, 11) ^ __ROR4__(v58, 6))
          + v47
          + v60
          + 1925078388;
      v117 = v48 + v61;
      v123 = v60;
      v62 = (v51 & v55 | (v51 | v55) & v59) + (__ROR4__(v59, 22) ^ __ROR4__(v59, 13) ^ __ROR4__(v59, 2)) + v61;
      v129 = bswap32(v119[13]);
      v63 = ((v54 ^ v58) & v117 ^ v54)
          + (__ROR4__(v117, 25) ^ __ROR4__(v117, 11) ^ __ROR4__(v117, 6))
          + v50
          + v129
          - 2132889090;
      v64 = v51 + v63;
      v65 = (v55 & v59 | (v55 | v59) & v62) + (__ROR4__(v62, 22) ^ __ROR4__(v62, 13) ^ __ROR4__(v62, 2)) + v63;
      v127 = bswap32(v119[14]);
      v66 = ((v117 ^ v58) & v64 ^ v58)
          + (__ROR4__(v64, 25) ^ __ROR4__(v64, 11) ^ __ROR4__(v64, 6))
          + v54
          + v127
          - 1680079193;
      v67 = v55 + v66;
      v68 = (v59 & v62 | (v59 | v62) & v65) + (__ROR4__(v65, 22) ^ __ROR4__(v65, 13) ^ __ROR4__(v65, 2)) + v66;
      v69 = v117;
      v70 = bswap32(v119[15]);
      v71 = ((v117 ^ v64) & v67 ^ v117)
          + (__ROR4__(v67, 25) ^ __ROR4__(v67, 11) ^ __ROR4__(v67, 6))
          + v58
          + v70
          - 1046744716;
      v135 = v70;
      v72 = v59 + v71;
      v73 = (v62 & v65 | (v62 | v65) & v68) + (__ROR4__(v68, 22) ^ __ROR4__(v68, 13) ^ __ROR4__(v68, 2)) + v71;
      v118 = &SymCryptSha256K[16];
      v136 = 3;
      do
      {
        v131 += (__ROR4__(v133, 7) ^ __ROR4__(v133, 18) ^ (v133 >> 3))
              + (__ROR4__(v127, 17) ^ __ROR4__(v127, 19) ^ (v127 >> 10))
              + v124;
        v149[0] = v131;
        v74 = *v118
            + (__ROR4__(v72, 25) ^ __ROR4__(v72, 11) ^ __ROR4__(v72, 6))
            + ((v64 ^ v67) & v72 ^ v64)
            + v69
            + v131;
        v75 = (v65 & v68 | (v65 | v68) & v73) + (__ROR4__(v73, 22) ^ __ROR4__(v73, 13) ^ __ROR4__(v73, 2)) + v74;
        v76 = v62 + v74;
        v133 += (__ROR4__(v122, 7) ^ __ROR4__(v122, 18) ^ (v122 >> 3))
              + (__ROR4__(v135, 17) ^ __ROR4__(v135, 19) ^ (v135 >> 10))
              + v126;
        v149[1] = v133;
        v77 = v118[1]
            + (__ROR4__(v76, 25) ^ __ROR4__(v76, 11) ^ __ROR4__(v76, 6))
            + ((v67 ^ v72) & v76 ^ v67)
            + v64
            + v133;
        v78 = v77 + v65;
        v79 = (v68 & v73 | (v68 | v73) & v75) + (__ROR4__(v75, 22) ^ __ROR4__(v75, 13) ^ __ROR4__(v75, 2)) + v77;
        v122 += (__ROR4__(v131, 17) ^ __ROR4__(v131, 19) ^ (v131 >> 10))
              + (__ROR4__(v132, 7) ^ __ROR4__(v132, 18) ^ (v132 >> 3))
              + v128;
        v149[2] = v122;
        v80 = v118[2]
            + (__ROR4__(v78, 25) ^ __ROR4__(v78, 11) ^ __ROR4__(v78, 6))
            + ((v72 ^ v76) & v78 ^ v72)
            + v67
            + v122;
        v81 = v80 + v68;
        v82 = (v75 & v73 | (v75 | v73) & v79) + (__ROR4__(v79, 22) ^ __ROR4__(v79, 13) ^ __ROR4__(v79, 2)) + v80;
        v132 += (__ROR4__(v133, 17) ^ __ROR4__(v133, 19) ^ (v133 >> 10))
              + (__ROR4__(v130, 7) ^ __ROR4__(v130, 18) ^ (v130 >> 3))
              + v123;
        v149[3] = v132;
        v83 = v118[3]
            + (__ROR4__(v81, 25) ^ __ROR4__(v81, 11) ^ __ROR4__(v81, 6))
            + ((v76 ^ v78) & v81 ^ v76)
            + v72
            + v132;
        v84 = v83 + v73;
        v85 = (v75 & v79 | (v75 | v79) & v82) + (__ROR4__(v82, 22) ^ __ROR4__(v82, 13) ^ __ROR4__(v82, 2)) + v83;
        v130 += (__ROR4__(v122, 17) ^ __ROR4__(v122, 19) ^ (v122 >> 10))
              + (__ROR4__(v134, 7) ^ __ROR4__(v134, 18) ^ (v134 >> 3))
              + v129;
        v149[4] = v130;
        v86 = v118[4]
            + (__ROR4__(v84, 25) ^ __ROR4__(v84, 11) ^ __ROR4__(v84, 6))
            + ((v78 ^ v81) & v84 ^ v78)
            + v76
            + v130;
        v87 = v75 + v86;
        v88 = (v79 & v82 | (v79 | v82) & v85) + (__ROR4__(v85, 22) ^ __ROR4__(v85, 13) ^ __ROR4__(v85, 2)) + v86;
        v134 += (__ROR4__(v132, 17) ^ __ROR4__(v132, 19) ^ (v132 >> 10))
              + (__ROR4__(v121, 7) ^ __ROR4__(v121, 18) ^ (v121 >> 3))
              + v127;
        v149[5] = v134;
        v89 = v118[5]
            + (__ROR4__(v87, 25) ^ __ROR4__(v87, 11) ^ __ROR4__(v87, 6))
            + ((v81 ^ v84) & v87 ^ v81)
            + v78
            + v134;
        v90 = v79 + v89;
        v91 = (v82 & v85 | (v82 | v85) & v88) + (__ROR4__(v88, 22) ^ __ROR4__(v88, 13) ^ __ROR4__(v88, 2)) + v89;
        v121 += (__ROR4__(v130, 17) ^ __ROR4__(v130, 19) ^ (v130 >> 10))
              + (__ROR4__(v125, 7) ^ __ROR4__(v125, 18) ^ (v125 >> 3))
              + v135;
        v149[6] = v121;
        v92 = v118[6]
            + (__ROR4__(v90, 25) ^ __ROR4__(v90, 11) ^ __ROR4__(v90, 6))
            + ((v87 ^ v84) & v90 ^ v84)
            + v81
            + v121;
        v93 = v82 + v92;
        v94 = (v85 & v88 | (v85 | v88) & v91) + (__ROR4__(v91, 22) ^ __ROR4__(v91, 13) ^ __ROR4__(v91, 2)) + v92;
        v125 += (__ROR4__(v134, 17) ^ __ROR4__(v134, 19) ^ (v134 >> 10))
              + (__ROR4__(v120, 7) ^ __ROR4__(v120, 18) ^ (v120 >> 3))
              + v131;
        v149[7] = v125;
        v95 = v118[7]
            + (__ROR4__(v93, 25) ^ __ROR4__(v93, 11) ^ __ROR4__(v93, 6))
            + ((v87 ^ v90) & v93 ^ v87)
            + v84
            + v125;
        v96 = v85 + v95;
        v97 = (v88 & v91 | (v88 | v91) & v94) + (__ROR4__(v94, 22) ^ __ROR4__(v94, 13) ^ __ROR4__(v94, 2)) + v95;
        v120 += (__ROR4__(v121, 17) ^ __ROR4__(v121, 19) ^ (v121 >> 10))
              + (__ROR4__(v124, 7) ^ __ROR4__(v124, 18) ^ (v124 >> 3))
              + v133;
        v149[8] = v120;
        v98 = v118[8]
            + (__ROR4__(v96, 25) ^ __ROR4__(v96, 11) ^ __ROR4__(v96, 6))
            + ((v90 ^ v93) & v96 ^ v90)
            + v87
            + v120;
        v99 = v98 + v88;
        v100 = (v91 & v94 | (v91 | v94) & v97) + (__ROR4__(v97, 22) ^ __ROR4__(v97, 13) ^ __ROR4__(v97, 2)) + v98;
        v124 += (__ROR4__(v125, 17) ^ __ROR4__(v125, 19) ^ (v125 >> 10))
              + (__ROR4__(v126, 7) ^ __ROR4__(v126, 18) ^ (v126 >> 3))
              + v122;
        v149[9] = v124;
        v101 = v118[9]
             + (__ROR4__(v99, 25) ^ __ROR4__(v99, 11) ^ __ROR4__(v99, 6))
             + ((v93 ^ v96) & v99 ^ v93)
             + v90
             + v124;
        v102 = v101 + v91;
        v103 = (v94 & v97 | (v94 | v97) & v100) + (__ROR4__(v100, 22) ^ __ROR4__(v100, 13) ^ __ROR4__(v100, 2)) + v101;
        v126 += (__ROR4__(v120, 17) ^ __ROR4__(v120, 19) ^ (v120 >> 10))
              + (__ROR4__(v128, 7) ^ __ROR4__(v128, 18) ^ (v128 >> 3))
              + v132;
        v149[10] = v126;
        v104 = v118[10]
             + (__ROR4__(v102, 25) ^ __ROR4__(v102, 11) ^ __ROR4__(v102, 6))
             + ((v96 ^ v99) & v102 ^ v96)
             + v93
             + v126;
        v105 = v104 + v94;
        v106 = (v100 & v97 | (v100 | v97) & v103) + (__ROR4__(v103, 22) ^ __ROR4__(v103, 13) ^ __ROR4__(v103, 2)) + v104;
        v128 += (__ROR4__(v124, 17) ^ __ROR4__(v124, 19) ^ (v124 >> 10))
              + (__ROR4__(v123, 7) ^ __ROR4__(v123, 18) ^ (v123 >> 3))
              + v130;
        v149[11] = v128;
        v107 = v118[11]
             + (__ROR4__(v105, 25) ^ __ROR4__(v105, 11) ^ __ROR4__(v105, 6))
             + ((v99 ^ v102) & v105 ^ v99)
             + v96
             + v128;
        v108 = v107 + v97;
        v109 = (v100 & v103 | (v100 | v103) & v106)
             + (__ROR4__(v106, 22) ^ __ROR4__(v106, 13) ^ __ROR4__(v106, 2))
             + v107;
        v123 += (__ROR4__(v126, 17) ^ __ROR4__(v126, 19) ^ (v126 >> 10))
              + (__ROR4__(v129, 7) ^ __ROR4__(v129, 18) ^ (v129 >> 3))
              + v134;
        v149[12] = v123;
        v110 = v118[12]
             + (__ROR4__(v108, 25) ^ __ROR4__(v108, 11) ^ __ROR4__(v108, 6))
             + ((v102 ^ v105) & v108 ^ v102)
             + v99
             + v123;
        v62 = (v103 & v106 | (v103 | v106) & v109)
            + (__ROR4__(v109, 22) ^ __ROR4__(v109, 13) ^ __ROR4__(v109, 2))
            + v110;
        v69 = v100 + v110;
        v129 += (__ROR4__(v128, 17) ^ __ROR4__(v128, 19) ^ (v128 >> 10))
              + (__ROR4__(v127, 7) ^ __ROR4__(v127, 18) ^ (v127 >> 3))
              + v121;
        v149[13] = v129;
        v111 = v118[13]
             + (__ROR4__(v69, 25) ^ __ROR4__(v69, 11) ^ __ROR4__(v69, 6))
             + ((v105 ^ v108) & v69 ^ v105)
             + v102
             + v129;
        v64 = v103 + v111;
        v65 = (v106 & v109 | (v106 | v109) & v62) + (__ROR4__(v62, 22) ^ __ROR4__(v62, 13) ^ __ROR4__(v62, 2)) + v111;
        v127 += (__ROR4__(v123, 17) ^ __ROR4__(v123, 19) ^ (v123 >> 10))
              + (__ROR4__(v135, 7) ^ __ROR4__(v135, 18) ^ (v135 >> 3))
              + v125;
        v149[14] = v127;
        v112 = v118[14]
             + (__ROR4__(v64, 25) ^ __ROR4__(v64, 11) ^ __ROR4__(v64, 6))
             + ((v69 ^ v108) & v64 ^ v108)
             + v105
             + v127;
        v67 = v106 + v112;
        v68 = (v109 & v62 | (v109 | v62) & v65) + (__ROR4__(v65, 22) ^ __ROR4__(v65, 13) ^ __ROR4__(v65, 2)) + v112;
        v135 += (__ROR4__(v131, 7) ^ __ROR4__(v131, 18) ^ (v131 >> 3))
              + (__ROR4__(v129, 17) ^ __ROR4__(v129, 19) ^ (v129 >> 10))
              + v120;
        v113 = v118[15];
        v149[15] = v135;
        v114 = v113
             + (__ROR4__(v67, 25) ^ __ROR4__(v67, 11) ^ __ROR4__(v67, 6))
             + ((v69 ^ v64) & v67 ^ v69)
             + v108
             + v135;
        v72 = v109 + v114;
        v73 = (v62 & v65 | (v62 | v65) & v68) + (__ROR4__(v68, 22) ^ __ROR4__(v68, 13) ^ __ROR4__(v68, 2)) + v114;
        v118 += 16;
        --v136;
      }
      while ( v136 );
      v5 = v68 + v143;
      v6 = v73 + v138;
      v7 = v65 + v140;
      *a1 = v6;
      a1[1] = v5;
      a1[2] = v7;
      v12 = v144 + v62;
      a1[3] = v144 + v62;
      v9 = v72 + v142;
      a1[4] = v9;
      v138 = v6;
      v8 = v67 + v146;
      a1[5] = v8;
      v143 = v5;
      v144 += v62;
      v10 = v64 + v145;
      a1[6] = v10;
      v140 = v7;
      v13 = v137 + v69;
      a1[7] = v137 + v69;
      a2 = v119 + 16;
      a3 = v139 - 64;
      v115 = v141-- == 1;
      v142 = v9;
      v145 = v10;
      v146 = v8;
      v137 = v13;
      v119 += 16;
      v139 -= 64;
    }
    while ( !v115 );
  }
  *a4 = a3;
  return SymCryptWipeAsm(v149, 64);
}
